<!DOCTYPE html>
<html lang="es">
  <head>
    <meta charset="UTF-8" />
    <title>Patito Parlante 🦆</title>
  </head>
  <body>
    <h1>🎙️ Patito Parlante con Detección de Silencio</h1>
    <button id="iniciar">Iniciar conversación</button>
    <button id="detener" disabled="true">Detener conversacion</button>
    <p id="estado">Esperando...</p>
    <audio id="player"></audio>
    <img src="./duck.jpg" id="image" alt="" width="200" height="200" />

    <script>
      const estado = document.getElementById("estado");
      const player = document.getElementById("player");
      const botonIniciar = document.getElementById("iniciar");
      const botondetener = document.getElementById("detener");
      const imagen = document.getElementById("image");
      let stream = null;
      let audioContext = null;
      let source = null;
      let analyser = null;
      let dataArray = null;
      let mediaRecorder = null;
      let conversacionActiva = false;
      let deleteimagecat = false;

      const umbralSilencio = 10; // volumen mínimo para considerar sonido
      const maxSilencio = 3000; // ms para detectar silencio (3 segundos)
      let ultimoSonido = Date.now();
      let grabando = false;

      // Función para iniciar la grabación con detección de silencio
      async function empezarGrabacion() {
        console.log("cambiando a escucha");
        if (!conversacionActiva) return;

        estado.textContent = "⏺️ Grabando... habla ahora";

        if (!stream) {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        }

        if (!audioContext) {
          audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
        }

        if (source) source.disconnect();
        source = audioContext.createMediaStreamSource(stream);

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);

        dataArray = new Uint8Array(analyser.frequencyBinCount);

        const chunks = [];
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
        console.log("tendria que cambiar a listen");
        imagen.src = "./listen.jpg";

        mediaRecorder.onstop = async () => {
          grabando = false;
          estado.textContent = "📤 Enviando audio al backend...";
          const blob = new Blob(chunks, { type: "audio/webm" });
          console.log("parar audio");
          if (!deleteimagecat) {
            imagen.src = "./cat.gif";
          }

          // Enviar audio grabado a /conversar
          try {
            const formData = new FormData();
            formData.append("audio", blob, "grabacion.webm");

            const response = await fetch("http://localhost:8000/conversar", {
              method: "POST",
              body: formData,
            });

            if (!response.ok) throw new Error("Error en el servidor");
            console.log();
            console.log(response);

            const contentType = response.headers.get("content-type") || "";

            if (contentType.includes("audio/wav") && !deleteimagecat) {
              console.log("no se detuvo en grabacion");
              imagen.src = "./talk.gif";
            }

            const patoBlob = await response.blob();

            const patoUrl = URL.createObjectURL(patoBlob);

            player.src = patoUrl;
            if (!deleteimagecat) {
            player.play();
            }
            estado.textContent = "🦆 El patito respondió. Escuchando...";

            player.onended = () => {
              // Cuando termine de reproducir, vuelve a grabar
              if (!deleteimagecat) {
                empezarGrabacion();
              }
            };
          } catch (err) {
            console.error("❌ Error al enviar o recibir audio:", err);
            estado.textContent = "❌ Error al comunicar con el servidor.";
          }
        };

        grabando = true;
        mediaRecorder.start();
        ultimoSonido = Date.now();

        // Función para detectar silencio y detener grabación
        function detectarSilencio() {
          analyser.getByteFrequencyData(dataArray);
          const volumen =
            dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

          if (volumen < umbralSilencio) {
            if (Date.now() - ultimoSonido > maxSilencio && grabando) {
              estado.textContent =
                "🛑 Silencio detectado, deteniendo grabación...";
              mediaRecorder.stop();
              // No detener stream para reusar
              return;
            }
          } else {
            ultimoSonido = Date.now();
          }

          if (grabando) {
            requestAnimationFrame(detectarSilencio);
          }
        }
        detectarSilencio();
      }

      // Función para iniciar la conversación (primer fetch a /iniciar)
      async function iniciarConversacion() {
        conversacionActiva = true;
        console.log("📡 Enviando solicitud a /iniciar");
        imagen.src = "./cat.gif";
        await new Promise((resolve) => setTimeout(resolve, 100)); // 👈 Forzamos render
        try {
          // Paso 1: obtener texto de la conversación
          const response = await fetch("http://127.0.0.1:8000/iniciar", {
            method: "GET",
          });

          if (!response.ok) {
            throw new Error("Error en /audio: " + response.status);
          }
          console.log(response);

          // 👇 Consumir el blob del audio
          const audioBlob = await response.blob();
          const audioUrl = URL.createObjectURL(audioBlob);

          // 👇 Reproducir
          const player = document.getElementById("player");
          player.src = audioUrl;
          console.log("llegamo aca");
          console.log(player);
          console.log("no se detuvo en iniciar");
          if (!deleteimagecat) {
            imagen.src = "./talk.gif";

            await player.play();
          }

          player.onended = () => {
            console.log("🎧 Reproducción terminada");
            if (!deleteimagecat) {
              empezarGrabacion();
            }
          };
        } catch (err) {
          console.error("❌ Error al iniciar conversación:", err);
          estado.textContent = "❌ Error al iniciar conversación.";
        }
      }

      async function detenerConversacion() {
        conversacionActiva = false;
        imagen.src = "./duck.jpg";
        await new Promise((resolve) => setTimeout(resolve, 100)); // 👈 Forzamos render
        estado.textContent = "🛑 Conversación detenida.";

        try {
          await fetch("http://127.0.0.1:8000/cerrar", { method: "GET" });
          console.log("Conversación cerrada en backend");
          botonIniciar.disabled = false;
        } catch (e) {
          console.error("Error cerrando backend:", e);
        }

        if (mediaRecorder && mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        }

        if (stream) {
          // Para liberar el micrófono
          stream.getTracks().forEach((track) => track.stop());
          stream = null;
        }

        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }

        // Aquí también podrías enviar el fetch a /cerrar si quieres limpiar backend
      }

      // Al apretar el botón, deshabilitar botón y empezar conversación
      botonIniciar.onclick = () => {
        console.log("boton iniciar");
        deleteimagecat = false;
        botonIniciar.disabled = true;
        botondetener.disabled = false;
        iniciarConversacion();
      };

      botondetener.onclick = () => {
        console.log("boton detener");
        deleteimagecat = true;
        player.pause();
        player.currentTime = 0;
        botonIniciar.disabled = false;
        botondetener.disabled = true;
        detenerConversacion();
      };
    </script>
  </body>
</html>
