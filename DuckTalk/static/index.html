<!DOCTYPE html>
<html lang="es">
  <head>
    <meta charset="UTF-8" />
    <title>Patito Parlante ğŸ¦†</title>
  </head>
  <body>
    <h1>ğŸ™ï¸ Patito Parlante con DetecciÃ³n de Silencio</h1>
    <button id="iniciar">Iniciar conversaciÃ³n</button>
    <button id="detener" disabled="true">Detener conversacion</button>
    <p id="estado">Esperando...</p>
    <audio id="player"></audio>
    <img src="./duck.jpg" id="image" alt="" width="200" height="200" />

    <script>
      const estado = document.getElementById("estado");
      const player = document.getElementById("player");
      const botonIniciar = document.getElementById("iniciar");
      const botondetener = document.getElementById("detener");
      const imagen = document.getElementById("image");
      let stream = null;
      let audioContext = null;
      let source = null;
      let analyser = null;
      let dataArray = null;
      let mediaRecorder = null;
      let conversacionActiva = false;
      let deleteimagecat = false;

      const umbralSilencio = 10; // volumen mÃ­nimo para considerar sonido
      const maxSilencio = 3000; // ms para detectar silencio (3 segundos)
      let ultimoSonido = Date.now();
      let grabando = false;

      // FunciÃ³n para iniciar la grabaciÃ³n con detecciÃ³n de silencio
      async function empezarGrabacion() {
        console.log("cambiando a escucha");
        if (!conversacionActiva) return;

        estado.textContent = "âºï¸ Grabando... habla ahora";

        if (!stream) {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        }

        if (!audioContext) {
          audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
        }

        if (source) source.disconnect();
        source = audioContext.createMediaStreamSource(stream);

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);

        dataArray = new Uint8Array(analyser.frequencyBinCount);

        const chunks = [];
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
        console.log("tendria que cambiar a listen");
        imagen.src = "./listen.jpg";

        mediaRecorder.onstop = async () => {
          grabando = false;
          estado.textContent = "ğŸ“¤ Enviando audio al backend...";
          const blob = new Blob(chunks, { type: "audio/webm" });
          console.log("parar audio");
          if (!deleteimagecat) {
            imagen.src = "./cat.gif";
          }

          // Enviar audio grabado a /conversar
          try {
            const formData = new FormData();
            formData.append("audio", blob, "grabacion.webm");

            const response = await fetch("http://localhost:8000/conversar", {
              method: "POST",
              body: formData,
            });

            if (!response.ok) throw new Error("Error en el servidor");
            console.log();
            console.log(response);

            const contentType = response.headers.get("content-type") || "";

            if (contentType.includes("audio/wav") && !deleteimagecat) {
              console.log("no se detuvo en grabacion");
              imagen.src = "./talk.gif";
            }

            const patoBlob = await response.blob();

            const patoUrl = URL.createObjectURL(patoBlob);

            player.src = patoUrl;
            if (!deleteimagecat) {
            player.play();
            }
            estado.textContent = "ğŸ¦† El patito respondiÃ³. Escuchando...";

            player.onended = () => {
              // Cuando termine de reproducir, vuelve a grabar
              if (!deleteimagecat) {
                empezarGrabacion();
              }
            };
          } catch (err) {
            console.error("âŒ Error al enviar o recibir audio:", err);
            estado.textContent = "âŒ Error al comunicar con el servidor.";
          }
        };

        grabando = true;
        mediaRecorder.start();
        ultimoSonido = Date.now();

        // FunciÃ³n para detectar silencio y detener grabaciÃ³n
        function detectarSilencio() {
          analyser.getByteFrequencyData(dataArray);
          const volumen =
            dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

          if (volumen < umbralSilencio) {
            if (Date.now() - ultimoSonido > maxSilencio && grabando) {
              estado.textContent =
                "ğŸ›‘ Silencio detectado, deteniendo grabaciÃ³n...";
              mediaRecorder.stop();
              // No detener stream para reusar
              return;
            }
          } else {
            ultimoSonido = Date.now();
          }

          if (grabando) {
            requestAnimationFrame(detectarSilencio);
          }
        }
        detectarSilencio();
      }

      // FunciÃ³n para iniciar la conversaciÃ³n (primer fetch a /iniciar)
      async function iniciarConversacion() {
        conversacionActiva = true;
        console.log("ğŸ“¡ Enviando solicitud a /iniciar");
        imagen.src = "./cat.gif";
        await new Promise((resolve) => setTimeout(resolve, 100)); // ğŸ‘ˆ Forzamos render
        try {
          // Paso 1: obtener texto de la conversaciÃ³n
          const response = await fetch("http://127.0.0.1:8000/iniciar", {
            method: "GET",
          });

          if (!response.ok) {
            throw new Error("Error en /audio: " + response.status);
          }
          console.log(response);

          // ğŸ‘‡ Consumir el blob del audio
          const audioBlob = await response.blob();
          const audioUrl = URL.createObjectURL(audioBlob);

          // ğŸ‘‡ Reproducir
          const player = document.getElementById("player");
          player.src = audioUrl;
          console.log("llegamo aca");
          console.log(player);
          console.log("no se detuvo en iniciar");
          if (!deleteimagecat) {
            imagen.src = "./talk.gif";

            await player.play();
          }

          player.onended = () => {
            console.log("ğŸ§ ReproducciÃ³n terminada");
            if (!deleteimagecat) {
              empezarGrabacion();
            }
          };
        } catch (err) {
          console.error("âŒ Error al iniciar conversaciÃ³n:", err);
          estado.textContent = "âŒ Error al iniciar conversaciÃ³n.";
        }
      }

      async function detenerConversacion() {
        conversacionActiva = false;
        imagen.src = "./duck.jpg";
        await new Promise((resolve) => setTimeout(resolve, 100)); // ğŸ‘ˆ Forzamos render
        estado.textContent = "ğŸ›‘ ConversaciÃ³n detenida.";

        try {
          await fetch("http://127.0.0.1:8000/cerrar", { method: "GET" });
          console.log("ConversaciÃ³n cerrada en backend");
          botonIniciar.disabled = false;
        } catch (e) {
          console.error("Error cerrando backend:", e);
        }

        if (mediaRecorder && mediaRecorder.state === "recording") {
          mediaRecorder.stop();
        }

        if (stream) {
          // Para liberar el micrÃ³fono
          stream.getTracks().forEach((track) => track.stop());
          stream = null;
        }

        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }

        // AquÃ­ tambiÃ©n podrÃ­as enviar el fetch a /cerrar si quieres limpiar backend
      }

      // Al apretar el botÃ³n, deshabilitar botÃ³n y empezar conversaciÃ³n
      botonIniciar.onclick = () => {
        console.log("boton iniciar");
        deleteimagecat = false;
        botonIniciar.disabled = true;
        botondetener.disabled = false;
        iniciarConversacion();
      };

      botondetener.onclick = () => {
        console.log("boton detener");
        deleteimagecat = true;
        player.pause();
        player.currentTime = 0;
        botonIniciar.disabled = false;
        botondetener.disabled = true;
        detenerConversacion();
      };
    </script>
  </body>
</html>
